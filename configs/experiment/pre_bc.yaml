# @package _global_

defaults:
  # - override /trainer: ddp
  - override /model: smart_nano_1M

model:
  model_config:
    lr: 5e-4
    lr_min_ratio: 1e-2
    token_processor:
      map_token_sampling: # open-loop
        num_k: 1 # for k nearest neighbors
        temp: 1.0 # uniform sampling
      agent_token_sampling: # closed-loop
        num_k: 1 # for k nearest neighbors
        temp: 1.0

ckpt_path: null
# ckpt_path: CKPT_FOR_RESUME.ckpt # to resume training

trainer:
  limit_train_batches: 1.0
  limit_val_batches: 0.01 # reduced to 1% for faster validation
  check_val_every_n_epoch: 1
  max_epochs: 64
  log_every_n_steps: 50 # more frequent logging
  num_sanity_val_steps: 2 # run a few validation steps before training

data:
  train_batch_size: 10
  val_batch_size: 10
  test_batch_size: 10
  num_workers: 10
